{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoadMap:\n",
    "Heterogeneous Graph:\n",
    "  Nodes:\n",
    "    Actor:\n",
    "      TotalMovies\n",
    "      GenreDistribution\n",
    "    Movie:\n",
    "      TitleID\n",
    "      Name\n",
    "      Runtime\n",
    "      Genre\n",
    "      IsAdult\n",
    "      ReleaseYear\n",
    "      RuntimeMinutes\n",
    "      Genres\n",
    "      TotalRatings\n",
    "      AvgRating\n",
    "      Box Office Revenue\n",
    "  Edges:\n",
    "    Actor -> Movie (Acted in Movie)\n",
    "    Actor -> Actor in Shared movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-cluster\n",
      "  Using cached torch_cluster-1.6.3.tar.gz (54 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-spline-conv\n",
      "  Using cached torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-geometric\n",
      "  Downloading torch_geometric-2.5.2-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m514.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from torch-sparse)\n",
      "  Downloading scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m552.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from torch-geometric)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (3.1.3)\n",
      "Collecting aiohttp (from torch-geometric)\n",
      "  Downloading aiohttp-3.9.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (2.31.0)\n",
      "Collecting pyparsing (from torch-geometric)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting scikit-learn (from torch-geometric)\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (5.9.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->torch-geometric)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->torch-geometric)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->torch-geometric)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->torch-geometric)\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m211.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp312-cp312-macosx_11_0_arm64.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.7/389.7 kB\u001b[0m \u001b[31m300.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m296.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m448.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/30.4 MB\u001b[0m \u001b[31m271.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m546.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m437.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m417.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-macosx_11_0_arm64.whl size=273737 sha256=9cc4ed4b3bea8abfb833e902bdca55832c3657f2a11e203a40e2375ca6c782a4\n",
      "  Stored in directory: /Users/gavin/Library/Caches/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-macosx_11_0_arm64.whl size=457420 sha256=4231a6ac7ab77f0d14c5dfa6f92c76a7d53f955db01057a8bb9a6f35600754c7\n",
      "  Stored in directory: /Users/gavin/Library/Caches/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
      "  Building wheel for torch-cluster (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp312-cp312-macosx_11_0_arm64.whl size=299072 sha256=dda51013949690107ed34b1c8cbf1cad1d7220ac24a3ff3d12daa40063e73f0f\n",
      "  Stored in directory: /Users/gavin/Library/Caches/pip/wheels/2e/8f/d0/13408a84825c9a587151a74727b4a6d47ec67e0d625b385ad7\n",
      "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp312-cp312-macosx_11_0_arm64.whl size=107584 sha256=5ff46ec42d635577ee33b6108f95d4c193cbd29a3f78796b8613718af3d7b5d5\n",
      "  Stored in directory: /Users/gavin/Library/Caches/pip/wheels/54/7a/2e/46a729dc0aad2da1a908b0d2ac86ab127d73e6b4310a945d07\n",
      "Successfully built torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
      "Installing collected packages: tqdm, torch-spline-conv, torch-scatter, threadpoolctl, scipy, pyparsing, multidict, joblib, frozenlist, attrs, yarl, torch-sparse, torch-cluster, scikit-learn, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 attrs-23.2.0 frozenlist-1.4.1 joblib-1.4.0 multidict-6.0.5 pyparsing-3.1.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.4.0 torch-cluster-1.6.3 torch-geometric-2.5.2 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2 tqdm-4.66.2 yarl-1.9.4\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyg-lib\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: mediawikiapi in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (1.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from mediawikiapi) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from mediawikiapi) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->mediawikiapi) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "! pip install pyg-lib -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
    "! pip install beautifulsoup4\n",
    "! pip install mediawikiapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform imports\n",
    "from csv import reader as CSVReader\n",
    "from csv import writer as CSVWriter\n",
    "from operator import itemgetter as itemgetter\n",
    "from mediawikiapi import MediaWikiAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 438832 lines out of 10822149 (4.05%)\n",
      "Genres (26):\n",
      "\tDrama: 157544\n",
      "\tDocumentary: 117247\n",
      "\tComedy: 76134\n",
      "\tAction: 37525\n",
      "\tThriller: 32705\n",
      "\tRomance: 31812\n",
      "\tHorror: 28477\n",
      "\tCrime: 24305\n",
      "\tAdventure: 17393\n",
      "\tBiography: 15654\n",
      "\tFamily: 14569\n",
      "\tMystery: 13438\n",
      "\tHistory: 11945\n",
      "\tMusic: 11287\n",
      "\tFantasy: 11047\n",
      "\tSci-Fi: 9033\n",
      "\tAnimation: 7906\n",
      "\tAdult: 6560\n",
      "\tSport: 6310\n",
      "\tWar: 4839\n",
      "\tMusical: 4576\n",
      "\tNews: 1634\n",
      "\tWestern: 1302\n",
      "\tReality-TV: 493\n",
      "\tTalk-Show: 163\n",
      "\tGame-Show: 21\n"
     ]
    }
   ],
   "source": [
    "# Trim based on minimum start year, \"movie\" classification and count genre frequencies\n",
    "\n",
    "inpath = \"data/title.basics.tsv\"\n",
    "outpath = \"data/title.basics_trimmed.tsv\"\n",
    "\n",
    "minStartYear = 1980\n",
    "\n",
    "genreFreq = {}\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  i = 0\n",
    "  j = 0\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    startStr = str(l[5])\n",
    "    type = str(l[1])\n",
    "    genres = str(l[8]).split(sep=',')\n",
    "    if ( (i != 0) and (startStr != \"\\\\N\") and (int(startStr) >= minStartYear) and type == \"movie\"):\n",
    "      writer.writerow(line)\n",
    "      for genre in genres:\n",
    "        if genre != \"\\\\N\":\n",
    "          if genre in genreFreq:\n",
    "            genreFreq[genre] += 1\n",
    "          else:\n",
    "            genreFreq[genre] = 1\n",
    "      j += 1\n",
    "    i += 1\n",
    "\n",
    "print(f\"Copied {j} lines out of {i} ({round((j / i) * 100, 2)}%)\")\n",
    "\n",
    "genreFreqItems = genreFreq.items()\n",
    "print(f\"Genres ({len(genreFreqItems)}):\")\n",
    "for genre, freq in sorted(genreFreqItems, key=itemgetter(1), reverse=True):\n",
    "  print(f\"\\t{genre}: {freq}\")\n",
    "\n",
    "del genreFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode genre list for each movie\n",
    "genreList = list(i[0] for i in genreFreqItems)\n",
    "\n",
    "inpath = \"data/title.basics_trimmed.tsv\"\n",
    "outpath = \"data/title.basics_genres_encoded.tsv\"\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    \n",
    "    encodedGenres = \"\"\n",
    "    genres = str(l[8]).split(sep=',')\n",
    "    for genre in genreList:\n",
    "      if genre in genres:\n",
    "        encodedGenres += '1'\n",
    "      else:\n",
    "        encodedGenres += '0' \n",
    "    newRow = l[:8]\n",
    "    newRow.append(encodedGenres)\n",
    "    writer.writerow(newRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 25975 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Trim out duplicate references to same movie\n",
    "\n",
    "inpath = \"data/title.basics_genres_encoded.tsv\"\n",
    "outpath = \"data/title_unique.tsv\"\n",
    "\n",
    "observedFeatures = set()\n",
    "\n",
    "numDuplicates = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    features = str(l[1:])\n",
    "    if not features in observedFeatures:\n",
    "      observedFeatures.add(features)\n",
    "      writer.writerow(l)\n",
    "    else:\n",
    "      numDuplicates += 1    \n",
    "\n",
    "del observedFeatures\n",
    "print(f\"Removed {numDuplicates} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim out unnecessary columns (titleType (1), originalTitle (2), endYear (6))\n",
    "\n",
    "inpath = \"data/title_unique.tsv\"\n",
    "outpath = \"data/processed/movies.tsv\"\n",
    "\n",
    "observedFeatures = set()\n",
    "\n",
    "numDuplicates = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    writer.writerow([l[0], l[3], l[4], l[5], l[7], l[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 97840 entries\n"
     ]
    }
   ],
   "source": [
    "# Drop movies that do not contain a runtime length value\n",
    "\n",
    "inpath = \"data/processed/movies.tsv\"\n",
    "outpath = \"data/processed/moviesRuntimes.tsv\"\n",
    "\n",
    "numRemoved = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    if (l[4] != \"\\\\N\"):\n",
    "      writer.writerow(l)\n",
    "    else:\n",
    "      numRemoved += 1\n",
    "\n",
    "print(f\"Removed {numRemoved} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 205605 lines\n"
     ]
    }
   ],
   "source": [
    "# Join movies with ratings data, discard those without ratings data\n",
    "\n",
    "inpathMovies = \"data/processed/moviesRuntimes.tsv\"\n",
    "inpathRatings = \"data/title.ratings.tsv\"\n",
    "outpath = \"data/processed/moviesRatings.tsv\"\n",
    "\n",
    "linesWritten = 0\n",
    "\n",
    "with open(inpathMovies, \"r\") as infileMovies, open(inpathRatings, \"r\") as infileRatings, open(outpath, \"w\") as outfile:\n",
    "  readerMovies = CSVReader(infileMovies, delimiter=\"\\t\", quotechar=None)\n",
    "  readerRatings = CSVReader(infileRatings, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  ratingsLine = next(readerRatings)\n",
    "  ratingsHeader = ratingsLine\n",
    "  # print(ratingsLine)\n",
    "  \n",
    "\n",
    "  for line in readerMovies:\n",
    "    l = list(line)\n",
    "\n",
    "    while (ratingsLine[0] < l[0] and len(ratingsHeader) == len(ratingsLine)):\n",
    "      # print(f\"\\\"{ratingsLine[0]}\\\"\", f\"\\\"{l[0]}\\\"\")\n",
    "      ratingsLine = next(readerRatings)\n",
    "    if (ratingsLine[0] == l[0]):\n",
    "      l.append(ratingsLine[1])\n",
    "      l.append(ratingsLine[2])\n",
    "      writer.writerow(l)\n",
    "      linesWritten += 1\n",
    "\n",
    "print(f\"Wrote {linesWritten} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carmencita', 'Carmencita Padilla', 'Angaria carmencita', 'Carmencita Reyes', 'Carmencita Lara', 'Carmencita Hederman', 'Carmencita (film)', 'Carmencita Calderón', 'Carmen Martínez-Bordiú', 'Carmencita (Corinth)']\n"
     ]
    }
   ],
   "source": [
    "mdwk = MediaWikiAPI()\n",
    "\n",
    "res = mdwk.search(\"Carmencita\")\n",
    "print(res)\n",
    "\n",
    "# pageTitle = str(res[0])\n",
    "# print(pageTitle)\n",
    "\n",
    "#print(mdwk.summary(\"Space_Jam\"))\n",
    "\n",
    "# titlestub = \"https://en.wikipedia.org/api/rest_v1/page/title/\"\n",
    "\n",
    "# page = mdwk.page(title=pageTitle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
