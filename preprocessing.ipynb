{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoadMap:\n",
    "Heterogeneous Graph:\n",
    "  Nodes:\n",
    "    Actor:\n",
    "      TotalMovies\n",
    "      GenreDistribution\n",
    "    Movie:\n",
    "      TitleID\n",
    "      Name\n",
    "      Runtime\n",
    "      Genre\n",
    "      IsAdult\n",
    "      ReleaseYear\n",
    "      RuntimeMinutes\n",
    "      Genres\n",
    "      TotalRatings\n",
    "      AvgRating\n",
    "      Box Office Revenue\n",
    "  Edges:\n",
    "    Actor -> Movie (Acted in Movie)\n",
    "    Actor -> Actor in Shared movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-scatter in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch-sparse in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (0.6.18)\n",
      "Requirement already satisfied: torch-cluster in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (1.6.3)\n",
      "Requirement already satisfied: torch-spline-conv in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (1.2.2)\n",
      "Requirement already satisfied: torch-geometric in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (2.5.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-sparse) (1.13.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (4.66.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from scikit-learn->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyg-lib\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: mediawikiapi in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (1.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.11.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from mediawikiapi) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from mediawikiapi) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.11.1->mediawikiapi) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/DL/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->mediawikiapi) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "! pip install pyg-lib -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
    "! pip install beautifulsoup4\n",
    "! pip install mediawikiapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform imports\n",
    "from csv import reader as CSVReader\n",
    "from csv import writer as CSVWriter\n",
    "from operator import itemgetter as itemgetter\n",
    "from mediawikiapi import MediaWikiAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 259763 lines out of 10716429 (2.42%)\n",
      "Genres (26):\n",
      "\tDrama: 90686\n",
      "\tDocumentary: 82723\n",
      "\tComedy: 44836\n",
      "\tAction: 18864\n",
      "\tThriller: 18573\n",
      "\tRomance: 18374\n",
      "\tHorror: 17214\n",
      "\tCrime: 12699\n",
      "\tBiography: 10592\n",
      "\tAdventure: 9856\n",
      "\tFamily: 8743\n",
      "\tMystery: 8020\n",
      "\tHistory: 8018\n",
      "\tMusic: 7663\n",
      "\tFantasy: 6249\n",
      "\tSci-Fi: 5089\n",
      "\tAnimation: 4670\n",
      "\tSport: 4333\n",
      "\tMusical: 2648\n",
      "\tWar: 2607\n",
      "\tAdult: 1463\n",
      "\tNews: 1317\n",
      "\tWestern: 728\n",
      "\tReality-TV: 373\n",
      "\tTalk-Show: 113\n",
      "\tGame-Show: 10\n"
     ]
    }
   ],
   "source": [
    "# Trim based on minimum start year, \"movie\" classification and count genre frequencies\n",
    "\n",
    "inpath = \"data/title.basics.tsv\"\n",
    "outpath = \"data/title.basics_trimmed.tsv\"\n",
    "\n",
    "minStartYear = 2000\n",
    "maxStartYear = 2020\n",
    "\n",
    "genreFreq = {}\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  i = 0\n",
    "  j = 0\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    startStr = str(l[5])\n",
    "    type = str(l[1])\n",
    "    genres = str(l[8]).split(sep=',')\n",
    "    if ( (i != 0) and (startStr != \"\\\\N\") and (int(startStr) >= minStartYear) and int(startStr) <= maxStartYear and type == \"movie\"):\n",
    "      writer.writerow(line)\n",
    "      for genre in genres:\n",
    "        if genre != \"\\\\N\":\n",
    "          if genre in genreFreq:\n",
    "            genreFreq[genre] += 1\n",
    "          else:\n",
    "            genreFreq[genre] = 1\n",
    "      j += 1\n",
    "    i += 1\n",
    "\n",
    "print(f\"Copied {j} lines out of {i} ({round((j / i) * 100, 2)}%)\")\n",
    "\n",
    "genreFreqItems = genreFreq.items()\n",
    "print(f\"Genres ({len(genreFreqItems)}):\")\n",
    "for genre, freq in sorted(genreFreqItems, key=itemgetter(1), reverse=True):\n",
    "  print(f\"\\t{genre}: {freq}\")\n",
    "\n",
    "del genreFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode genre list for each movie\n",
    "genreList = list(i[0] for i in genreFreqItems)\n",
    "\n",
    "inpath = \"data/title.basics_trimmed.tsv\"\n",
    "outpath = \"data/title.basics_genres_encoded.tsv\"\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    \n",
    "    encodedGenres = \"\"\n",
    "    genres = str(l[8]).split(sep=',')\n",
    "    for genre in genreList:\n",
    "      if genre in genres:\n",
    "        encodedGenres += '1'\n",
    "      else:\n",
    "        encodedGenres += '0' \n",
    "    newRow = l[:8]\n",
    "    newRow.append(encodedGenres)\n",
    "    writer.writerow(newRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 168 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Trim out duplicate references to same movie\n",
    "\n",
    "inpath = \"data/title.basics_genres_encoded.tsv\"\n",
    "outpath = \"data/title_unique.tsv\"\n",
    "\n",
    "observedFeatures = set()\n",
    "\n",
    "numDuplicates = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    features = str(l[1:])\n",
    "    if not features in observedFeatures:\n",
    "      observedFeatures.add(features)\n",
    "      writer.writerow(l)\n",
    "    else:\n",
    "      numDuplicates += 1    \n",
    "\n",
    "del observedFeatures\n",
    "print(f\"Removed {numDuplicates} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim out unnecessary columns (titleType (1), originalTitle (2), isAdult (4), endYear (6))\n",
    "\n",
    "inpath = \"data/title_unique.tsv\"\n",
    "outpath = \"data/processed/movies.tsv\"\n",
    "\n",
    "observedFeatures = set()\n",
    "\n",
    "numDuplicates = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    writer.writerow([l[0], l[3], l[5], l[7], l[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 52939 entries\n"
     ]
    }
   ],
   "source": [
    "# Drop movies that do not contain a runtime length value\n",
    "\n",
    "inpath = \"data/processed/movies.tsv\"\n",
    "outpath = \"data/processed/moviesRuntimes.tsv\"\n",
    "\n",
    "numRemoved = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    if (l[3] != \"\\\\N\"):\n",
    "      writer.writerow(l)\n",
    "    else:\n",
    "      numRemoved += 1\n",
    "\n",
    "print(f\"Removed {numRemoved} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 6560 lines\n"
     ]
    }
   ],
   "source": [
    "# Join movies with ratings data, discard those without ratings data or with less than minRatingsCount total ratings\n",
    "\n",
    "inpathMovies = \"data/processed/moviesRuntimes.tsv\"\n",
    "inpathRatings = \"data/title.ratings.tsv\"\n",
    "outpath = \"data/processed/moviesRatings.tsv\"\n",
    "\n",
    "minRatingsCount = 10000\n",
    "\n",
    "linesWritten = 0\n",
    "\n",
    "with open(inpathMovies, \"r\") as infileMovies, open(inpathRatings, \"r\") as infileRatings, open(outpath, \"w\") as outfile:\n",
    "  readerMovies = CSVReader(infileMovies, delimiter=\"\\t\", quotechar=None)\n",
    "  readerRatings = CSVReader(infileRatings, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  ratingsLine = next(readerRatings)\n",
    "  ratingsHeader = ratingsLine\n",
    "  # print(ratingsLine)\n",
    "  \n",
    "\n",
    "  for line in readerMovies:\n",
    "    l = list(line)\n",
    "\n",
    "    while (ratingsLine[0] < l[0] and len(ratingsHeader) == len(ratingsLine)):\n",
    "      # print(f\"\\\"{ratingsLine[0]}\\\"\", f\"\\\"{l[0]}\\\"\")\n",
    "      ratingsLine = next(readerRatings)\n",
    "    if (ratingsLine[0] == l[0] and int(ratingsLine[2]) >= minRatingsCount):\n",
    "      l.append(ratingsLine[1])\n",
    "      l.append(ratingsLine[2])\n",
    "      writer.writerow(l)\n",
    "      linesWritten += 1\n",
    "\n",
    "print(f\"Wrote {linesWritten} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final movies files\n",
    "inpath=\"data/processed/moviesRatings.tsv\"\n",
    "\n",
    "outpathData=\"data/final/movies.data.tsv\"\n",
    "outpathLabels=\"data/final/movies.labels.tsv\"\n",
    "\n",
    "existingTitles = set()\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpathData, \"w\") as outfileData, open(outpathLabels, \"w\") as outfileLabels:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writerData = CSVWriter(outfileData, delimiter=\"\\t\")\n",
    "  writerLabels = CSVWriter(outfileLabels, delimiter=\"\\t\")\n",
    "  \n",
    "  writerLabels.writerow([\"TitleID\", \"TitleName\"])\n",
    "  writerData.writerow([\"TitleID\", \"ReleaseYear\", \"RuntimeMinutes\", \"AvgRatings\", \"NumRatings\", \"Genres\"])\n",
    "\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    # print(l)\n",
    "    writerLabels.writerow([l[0], l[1]])\n",
    "    writerData.writerow([l[0], l[2], l[3], l[5], l[6], l[4]])\n",
    "    existingTitles.add(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows written: 144422\n",
      "Categories: (13):\n",
      "producer\n",
      "director\n",
      "actress\n",
      "production_designer\n",
      "self\n",
      "cinematographer\n",
      "archive_footage\n",
      "casting_director\n",
      "actor\n",
      "archive_sound\n",
      "composer\n",
      "writer\n",
      "editor\n"
     ]
    }
   ],
   "source": [
    "# Trim down \"principals\" data\n",
    "inpath=\"data/title.principals.tsv\"\n",
    "outpath=\"data/title.principals_trimmed.tsv\"\n",
    "\n",
    "numPrincipals = dict()\n",
    "categories = set()\n",
    "moviesPerPerson = dict()\n",
    "\n",
    "i = 0\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  first = True\n",
    "  for line in reader:\n",
    "    if (first):\n",
    "      first = False\n",
    "      continue\n",
    "    l = list(line)\n",
    "    # TitleID (0), Ordering (1), NameId (2), Category (3), Job (4), Characters (5)\n",
    "    if (l[0] in existingTitles):\n",
    "      if (l[0] in numPrincipals):\n",
    "        numPrincipals[l[0]] = max(int(l[1]), numPrincipals[l[0]])\n",
    "      else:\n",
    "        numPrincipals[l[0]] = (int(l[1]))\n",
    "      if (l[2] in moviesPerPerson):\n",
    "        moviesPerPerson[l[2]].add(l[0])\n",
    "      else:\n",
    "        moviesPerPerson[l[2]] = set()\n",
    "        moviesPerPerson[l[2]].add(l[0])\n",
    "      writer.writerow([l[0], l[2], l[3]])\n",
    "      categories.add(l[3])\n",
    "      i += 1\n",
    "\n",
    "print(f\"Rows written: {i}\")\n",
    "print(f\"Categories: ({len(categories)}):\")\n",
    "for category in categories:\n",
    "  print(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 55911 lines\n",
      "Primary Professions (47):\n",
      "legal\n",
      "production_department\n",
      "art_director\n",
      "electrical_department\n",
      "production_manager\n",
      "cinematographer\n",
      "actor\n",
      "script_department\n",
      "casting_department\n",
      "podcaster\n",
      "assistant\n",
      "assistant_director\n",
      "executive\n",
      "production_designer\n",
      "accountant\n",
      "art_department\n",
      "talent_agent\n",
      "archive_sound\n",
      "choreographer\n",
      "writer\n",
      "special_effects\n",
      "actress\n",
      "soundtrack\n",
      "publicist\n",
      "animation_department\n",
      "editorial_department\n",
      "costume_department\n",
      "archive_footage\n",
      "make_up_department\n",
      "\\N\n",
      "manager\n",
      "composer\n",
      "editor\n",
      "producer\n",
      "visual_effects\n",
      "director\n",
      "stunts\n",
      "location_management\n",
      "transportation_department\n",
      "camera_department\n",
      "music_artist\n",
      "set_decorator\n",
      "casting_director\n",
      "miscellaneous\n",
      "sound_department\n",
      "music_department\n",
      "costume_designer\n"
     ]
    }
   ],
   "source": [
    "# Trim down \"names\" data\n",
    "inpath=\"data/name.basics.tsv\"\n",
    "outpath=\"data/name.basics_trimmed.tsv\"\n",
    "\n",
    "primaryProfessionsList = set()\n",
    "i = 0\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  first = True\n",
    "  for line in reader:\n",
    "    if (first):\n",
    "      first = False\n",
    "      continue\n",
    "    l = list(line)\n",
    "    # NameId (0), PrimaryName (1), BirthYear (2), DeathYear (3), PrimaryProfession (4), KnownForTitles (5)\n",
    "\n",
    "    for profession in l[4].split(sep=','):\n",
    "      primaryProfessionsList.add(profession)\n",
    "\n",
    "    if (l[0] in moviesPerPerson):\n",
    "      writer.writerow([l[0], l[1], l[2], l[4], len(moviesPerPerson[l[0]])])\n",
    "      i += 1\n",
    "\n",
    "print(f\"Wrote {i} lines\")\n",
    "print(f\"Primary Professions ({len(primaryProfessionsList)}):\")\n",
    "for profession in primaryProfessionsList:\n",
    "  print(profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 55911 lines\n"
     ]
    }
   ],
   "source": [
    "# Encode professions data and write labels and values out to final versions\n",
    "inpath=\"data/name.basics_trimmed.tsv\"\n",
    "outpathLabels=\"data/final/person.labels.tsv\"\n",
    "outpathData=\"data/final/person.data.tsv\"\n",
    "\n",
    "i = 0\n",
    "\n",
    "with open(inpath, \"r\") as infile, open(outpathLabels, \"w\") as outfileLabels, open(outpathData, \"w\") as outfileData:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writerLabels = CSVWriter(outfileLabels, delimiter=\"\\t\")\n",
    "  writerData = CSVWriter(outfileData, delimiter=\"\\t\")\n",
    "\n",
    "  writerLabels.writerow([\"NameID\", \"PrimaryName\"])\n",
    "  writerData.writerow([\"NameID\", \"BirthYear\", \"PrimaryProfessions\", \"MoviesWorkedOn\"])\n",
    "\n",
    "  for line in reader:\n",
    "    \n",
    "    l = list(line)\n",
    "    # NameId (0), PrimaryName (1), BirthYear (2), PrimaryProfession (3), moviesWorkedOn (4)\n",
    "    encodedProfessions = \"\"\n",
    "    professions = str(l[3]).split(sep=',')\n",
    "    for profession in primaryProfessionsList:\n",
    "      if profession in professions:\n",
    "        encodedProfessions += '1'\n",
    "      else:\n",
    "        encodedProfessions += '0'\n",
    "\n",
    "\n",
    "    writerLabels.writerow([l[0], l[1]])\n",
    "    writerData.writerow([l[0], l[2], encodedProfessions, l[4]])\n",
    "    i += 1\n",
    "\n",
    "print(f\"Wrote {i} lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows written: 144422\n"
     ]
    }
   ],
   "source": [
    "# Establish \"WorksInMovie\" edges and count shared works between people\n",
    "inpath=\"data/title.principals_trimmed.tsv\"\n",
    "outpath=\"data/final/works_on.edge.tsv\"\n",
    "\n",
    "categoriesList = list(categories)\n",
    "\n",
    "i = 0\n",
    "with open(inpath, \"r\") as infile, open(outpath, \"w\") as outfile:\n",
    "  reader = CSVReader(infile, delimiter=\"\\t\", quotechar=None)\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  writer.writerow([\"NameID\", \"TitleID\", \"Category\"])\n",
    "  for line in reader:\n",
    "    l = list(line)\n",
    "    # TitleId (0), NameID (1), Category (2)\n",
    "    writer.writerow([l[1], l[0], categoriesList.index(l[2])])\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(f\"Rows written: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nm0000212'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person \u001b[38;5;129;01min\u001b[39;00m sharedMovies\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     23\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m person2 \u001b[38;5;129;01min\u001b[39;00m sharedMovies[person]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 24\u001b[0m     \u001b[43msharedMoviesCounts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperson\u001b[49m\u001b[43m]\u001b[49m[person2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sharedMovies[person][person2])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Write calculated edges out to file\u001b[39;00m\n\u001b[1;32m     27\u001b[0m outpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/final/shares_movies.edge.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nm0000212'"
     ]
    }
   ],
   "source": [
    "# Create \"SharesMovie\" Edges\n",
    "\n",
    "# person1 -> person2 -> [movie1, movie2, ..., movieN]\n",
    "\n",
    "sharedMovies = dict()\n",
    "\n",
    "for person in moviesPerPerson.keys():\n",
    "  for movie in moviesPerPerson[person]:\n",
    "    for person2 in moviesPerPerson.keys():\n",
    "      if (person < person2): # Should avoid repeats and self edges\n",
    "        # print(f\"P1: {person}, P2: {person2}\")\n",
    "        if (movie in moviesPerPerson[person2]): # Movie is shared by person and person2\n",
    "          if not (person in sharedMovies):\n",
    "            sharedMovies[person] = dict()\n",
    "          if not (person2 in sharedMovies[person]):\n",
    "            sharedMovies[person][person2] = set()\n",
    "          sharedMovies[person][person2].add(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count elements in shared sets\n",
    "sharedMoviesCounts = dict()\n",
    "for person in sharedMovies.keys():\n",
    "  for person2 in sharedMovies[person].keys():\n",
    "    if not (person in sharedMoviesCounts):\n",
    "      sharedMoviesCounts[person] = dict()\n",
    "    sharedMoviesCounts[person][person2] = len(sharedMovies[person][person2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows written: 1241937\n"
     ]
    }
   ],
   "source": [
    "# Write calculated edges out to file\n",
    "outpath=\"data/final/shares_movies.edge.tsv\"\n",
    "\n",
    "i = 0\n",
    "with open(outpath, \"w\") as outfile:\n",
    "  writer = CSVWriter(outfile, delimiter=\"\\t\")\n",
    "\n",
    "  writer.writerow([\"NameID1\", \"NameID2\", \"NumShared\"])\n",
    "  for person in sharedMovies.keys():\n",
    "    for person2 in sharedMovies[person].keys():\n",
    "      writer.writerow([str(person), str(person2), str(sharedMoviesCounts[person][person2])])\n",
    "      i += 1\n",
    "\n",
    "print(f\"Rows written: {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
